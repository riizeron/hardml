{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost.datasets import msrank_10k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = msrank_10k()\n",
    "\n",
    "X_train = train_df.drop([0, 1], axis=1).values\n",
    "y_train = train_df[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, y_train.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_train[[0,1], :][:, [0,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from typing import Tuple\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gain(y_value: float) -> float:\n",
    "    return float(2 ** y_value - 1)\n",
    "\n",
    "def dcg(ys_true: torch.Tensor, ys_pred: torch.Tensor,) -> float:\n",
    "    _, argsort = torch.sort(ys_pred, descending=True, dim=0)\n",
    "    ys_true_sorted = ys_true[argsort]\n",
    "    ret = 0\n",
    "    for idx, cur_y in enumerate(ys_true_sorted, 1):\n",
    "        gain = compute_gain(cur_y)\n",
    "        ret += gain / math.log2(idx + 1)\n",
    "    return ret\n",
    "\n",
    "\n",
    "def ndcg(ys_true: torch.Tensor, ys_pred: torch.Tensor) -> float:\n",
    "    pred_dcg = dcg(ys_true, ys_pred)\n",
    "    ideal_dcg = dcg(ys_true, ys_true)\n",
    "    \n",
    "    if ideal_dcg:\n",
    "        return pred_dcg / ideal_dcg\n",
    "    \n",
    "    return 0\n",
    "\n",
    "def compute_ideal_dcg(ys_true):\n",
    "    return dcg(ys_true, ys_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _compute_lambdas(y_true: torch.FloatTensor, y_pred: torch.FloatTensor) -> torch.FloatTensor:\n",
    "    ideal_dcg = compute_ideal_dcg(y_true)\n",
    "    N = 1 / ideal_dcg if ideal_dcg != 0 else 0\n",
    "    \n",
    "    # рассчитаем порядок документов согласно оценкам релевантности\n",
    "    _, rank_order = torch.sort(y_true, descending=True, axis=0)\n",
    "    rank_order += 1\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # получаем все попарные разницы скоров в батче\n",
    "        pos_pairs_score_diff = 1.0 + torch.exp(torch.Tensor(y_pred - y_pred.T))\n",
    "        \n",
    "        # поставим разметку для пар, 1 если первый документ релевантнее\n",
    "        # -1 если второй документ релевантнее\n",
    "        Sij = compute_labels_in_batch(y_true)\n",
    "        # посчитаем изменение gain из-за перестановок\n",
    "        gain_diff = compute_gain_diff(y_true)\n",
    "        \n",
    "        # посчитаем изменение знаменателей-дискаунтеров\n",
    "        decay_diff = (1.0 / torch.log2(rank_order + 1.0)) - (1.0 / torch.log2(rank_order.T + 1.0))\n",
    "        # посчитаем непосредственное изменение nDCG\n",
    "        delta_ndcg = torch.abs(N * gain_diff * decay_diff)\n",
    "        # посчитаем лямбды\n",
    "        lambda_update =  (0.5 * (1 - Sij) - 1 / pos_pairs_score_diff) * delta_ndcg\n",
    "        lambda_update = torch.sum(lambda_update, dim=1, keepdim=True)\n",
    "        \n",
    "        return lambda_update\n",
    "\n",
    "    \n",
    "def compute_labels_in_batch(y_true: torch.Tensor):\n",
    "    \n",
    "    # разница релевантностей каждого с каждым объектом\n",
    "    rel_diff = y_true - y_true.T\n",
    "    \n",
    "    # 1 в этой матрице - объект более релевантен\n",
    "    pos_pairs = (rel_diff > 0).type(torch.float32)\n",
    "    \n",
    "    # 1 тут - объект менее релевантен\n",
    "    neg_pairs = (rel_diff < 0).type(torch.float32)\n",
    "    Sij = pos_pairs - neg_pairs\n",
    "    return Sij\n",
    "\n",
    "def compute_gain_diff(y_true: torch.Tensor):\n",
    "   return torch.pow(2.0, y_true) - torch.pow(2.0, y_true.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  13,   13,   13, ..., 1303, 1318, 1318])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df, test_df = msrank_10k()\n",
    "\n",
    "# train_df = train_df[train_df[1] == 1]\n",
    "# test_df = test_df[test_df[1] == 13]\n",
    "\n",
    "X_train = train_df.drop([0, 1], axis=1).values\n",
    "y_train = train_df[0].values\n",
    "query_ids_train = train_df[1].values.astype(int)\n",
    "\n",
    "X_test = test_df.drop([0, 1], axis=1).values\n",
    "y_test = test_df[0].values\n",
    "query_ids_test = test_df[1].values.astype(int)\n",
    "\n",
    "query_ids_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _scale_features_in_query_groups(inp_feat_array: np.ndarray,\n",
    "                                        inp_query_ids: np.ndarray) -> np.ndarray:\n",
    "\n",
    "    for q in np.unique(inp_query_ids):\n",
    "        idx = (inp_query_ids == q).nonzero()\n",
    "        inp_feat_array[idx] = StandardScaler().fit_transform(inp_feat_array[idx])\n",
    "    \n",
    "    return inp_feat_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.3161,  4.8171, -2.1759,  ..., -0.1118, -0.1959, -0.2662],\n",
       "         [ 0.3161, -0.2350,  0.6171,  ..., -0.1118, -0.1959, -0.2662],\n",
       "         [ 0.3161, -0.2350, -0.3139,  ..., -0.1118, -0.1959, -0.2662],\n",
       "         ...,\n",
       "         [ 0.4786, -0.4121,  1.3276,  ...,  0.0000, -0.1552, -0.3721],\n",
       "         [ 0.4786, -0.4121, -0.0675,  ...,  0.0000, -0.1552, -0.3721],\n",
       "         [ 0.4786,  1.7170, -0.0675,  ...,  0.0000, -0.1552, -0.3721]]),\n",
       " tensor([[2.],\n",
       "         [2.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [2.],\n",
       "         [2.],\n",
       "         [1.]]))"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = torch.FloatTensor(_scale_features_in_query_groups(X_train, query_ids_train))\n",
    "ys_train = torch.FloatTensor(y_train).reshape(-1,1)\n",
    "\n",
    "X_test = torch.FloatTensor(_scale_features_in_query_groups(X_test, query_ids_test))\n",
    "ys_test = torch.FloatTensor(y_test).reshape(-1,1)\n",
    "\n",
    "X_train, ys_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gain(x):\n",
    "     return 2 ** x - 1\n",
    "\n",
    "def _ndcg_k(ys_true, ys_pred, ndcg_top_k) -> float:\n",
    "\n",
    "        ys_pred_k = ys_pred[:ndcg_top_k]\n",
    "        ys_true_k = ys_true[:ndcg_top_k]\n",
    "        \n",
    "        ys_pred_ind = torch.argsort(torch.Tensor(ys_pred_k), descending=True, dim=0)\n",
    "        ys_true_cons_sorted = ys_true_k[ys_pred_ind]\n",
    "\n",
    "        dcg_k = 0\n",
    "        for i, v in enumerate(ys_true_cons_sorted):\n",
    "            dcg_k += gain(v)/math.log2(i+2)\n",
    "\n",
    "\n",
    "        ys_true_sorted, _ = torch.sort(ys_true_k, descending=True, dim=0)\n",
    "\n",
    "        ideal_dcg_k = 0\n",
    "        for i, v in enumerate(ys_true_sorted):\n",
    "            ideal_dcg_k += gain(v)/math.log2(i+2)\n",
    "        \n",
    "        if ideal_dcg_k:\n",
    "            return float(dcg_k / ideal_dcg_k)\n",
    "        \n",
    "        return 0.\n",
    "\n",
    "def _calc_data_ndcg(queries_list: np.ndarray,\n",
    "                        true_labels: torch.FloatTensor, preds: torch.FloatTensor) -> float:\n",
    "\n",
    "    with torch.no_grad():\n",
    "        ndcgs = []\n",
    "\n",
    "        for q in np.unique(queries_list):\n",
    "            idx = (queries_list == q).nonzero()\n",
    "            batch_x = preds[idx]\n",
    "            batch_y = true_labels[idx]\n",
    "            \n",
    "            ndcgs.append(_ndcg_k(batch_y, batch_x, ndcg_top_k=10))\n",
    "        return np.mean(ndcgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsamples = 0.3\n",
    "colsample_bytree = 0.3\n",
    "\n",
    "lr = 0.1\n",
    "n_estimators = 100\n",
    "\n",
    "trees = []\n",
    "f_inds = []\n",
    "\n",
    "def predict(data):\n",
    "    res = torch.zeros_like(data[:,0].reshape(-1,1))\n",
    "    for tree, f in zip(trees, f_inds):\n",
    "        res -= lr * torch.FloatTensor(tree.predict(data[:,f])).reshape(-1,1)\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_tree(cur_tree_idx: int,\n",
    "                        train_preds: torch.FloatTensor\n",
    "                        ) -> Tuple[DecisionTreeRegressor, np.ndarray]:\n",
    "        \n",
    "    sample_length = int(subsamples * X_train.size(0))\n",
    "    colsample_bytree_length = int(colsample_bytree * X_train.size(1))\n",
    "\n",
    "    query_lambdas = torch.zeros_like(ys_train)\n",
    "    for q in np.unique(query_ids_train):\n",
    "        idx = (q == query_ids_train).nonzero()[0]\n",
    "        lambdas = _compute_lambdas(ys_train[idx], train_preds[idx])\n",
    "\n",
    "        for i, l in enumerate(lambdas):\n",
    "            query_lambdas[idx[i]] = l\n",
    "    \n",
    "    train_ind = torch.randperm(X_train.size(0))[:sample_length]\n",
    "    feature_ind = torch.randperm(X_train.size(1))[:colsample_bytree_length]\n",
    "\n",
    "    train = X_train[train_ind, :][:, feature_ind]\n",
    "    tree = DecisionTreeRegressor(random_state=i, max_depth=5, min_samples_leaf=8)\n",
    "    tree.fit(train, query_lambdas[train_ind])\n",
    "\n",
    "    return tree, feature_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "est. 0\n",
      "NDCG: 0.5868012278594754\n",
      "est. 1\n",
      "NDCG: 0.6257973296398466\n",
      "est. 2\n",
      "NDCG: 0.6406590058044954\n",
      "est. 3\n",
      "NDCG: 0.6448476883498105\n",
      "est. 4\n",
      "NDCG: 0.6332731951366771\n",
      "est. 5\n",
      "NDCG: 0.6381299983371388\n",
      "est. 6\n",
      "NDCG: 0.6212337159297683\n",
      "est. 7\n",
      "NDCG: 0.624439345842058\n",
      "est. 8\n",
      "NDCG: 0.629209215329452\n",
      "est. 9\n",
      "NDCG: 0.6294910531829704\n",
      "est. 10\n",
      "NDCG: 0.6314435574141416\n",
      "est. 11\n",
      "NDCG: 0.6321063583547418\n",
      "est. 12\n",
      "NDCG: 0.6336471072652123\n",
      "est. 13\n",
      "NDCG: 0.6339108757674694\n",
      "est. 14\n",
      "NDCG: 0.6350872479379177\n",
      "est. 15\n",
      "NDCG: 0.6347528838298537\n",
      "est. 16\n",
      "NDCG: 0.6277794268998232\n",
      "est. 17\n",
      "NDCG: 0.6239526163447987\n",
      "est. 18\n",
      "NDCG: 0.6256190013479103\n",
      "est. 19\n",
      "NDCG: 0.6232688071375544\n",
      "est. 20\n",
      "NDCG: 0.6139760332351382\n",
      "est. 21\n",
      "NDCG: 0.6195109249515967\n",
      "est. 22\n",
      "NDCG: 0.6215319101783362\n",
      "est. 23\n",
      "NDCG: 0.6333920078521426\n",
      "est. 24\n",
      "NDCG: 0.6328004293821075\n",
      "est. 25\n",
      "NDCG: 0.6404187845235522\n",
      "est. 26\n",
      "NDCG: 0.6469623605636033\n",
      "est. 27\n",
      "NDCG: 0.6469752544706519\n",
      "est. 28\n",
      "NDCG: 0.6461223509501327\n",
      "est. 29\n",
      "NDCG: 0.6509703942997889\n",
      "est. 30\n",
      "NDCG: 0.6485067189417102\n",
      "est. 31\n",
      "NDCG: 0.6463537934151563\n",
      "est. 32\n",
      "NDCG: 0.6438411589373242\n",
      "est. 33\n",
      "NDCG: 0.6412403553046964\n",
      "est. 34\n",
      "NDCG: 0.6446050828830763\n",
      "est. 35\n",
      "NDCG: 0.6397014236585661\n",
      "est. 36\n",
      "NDCG: 0.638465809889815\n",
      "est. 37\n",
      "NDCG: 0.6378646939992905\n",
      "est. 38\n",
      "NDCG: 0.6371405283835802\n",
      "est. 39\n",
      "NDCG: 0.6388034231283448\n",
      "est. 40\n",
      "NDCG: 0.6409279165620153\n",
      "est. 41\n",
      "NDCG: 0.6474925123832442\n",
      "est. 42\n",
      "NDCG: 0.6489398042586717\n",
      "est. 43\n",
      "NDCG: 0.6435472907667811\n",
      "est. 44\n",
      "NDCG: 0.643077530305494\n",
      "est. 45\n",
      "NDCG: 0.6392492167651653\n",
      "est. 46\n",
      "NDCG: 0.6432518904859369\n",
      "est. 47\n",
      "NDCG: 0.6440270780162378\n",
      "est. 48\n",
      "NDCG: 0.6442795297638937\n",
      "est. 49\n",
      "NDCG: 0.642564878883687\n",
      "est. 50\n",
      "NDCG: 0.6437434527007017\n",
      "est. 51\n",
      "NDCG: 0.6429962417618795\n",
      "est. 52\n",
      "NDCG: 0.6467997699298642\n",
      "est. 53\n",
      "NDCG: 0.6443200632929802\n",
      "est. 54\n",
      "NDCG: 0.6460308100689541\n",
      "est. 55\n",
      "NDCG: 0.6479036763987758\n",
      "est. 56\n",
      "NDCG: 0.6480277248404243\n",
      "est. 57\n",
      "NDCG: 0.6471025835384022\n",
      "est. 58\n",
      "NDCG: 0.6446673748168078\n",
      "est. 59\n",
      "NDCG: 0.644490011036396\n",
      "est. 60\n",
      "NDCG: 0.6461237980560823\n",
      "est. 61\n",
      "NDCG: 0.6467204395342957\n",
      "est. 62\n",
      "NDCG: 0.6471773138777777\n",
      "est. 63\n",
      "NDCG: 0.6475702060217207\n",
      "est. 64\n",
      "NDCG: 0.645114638927308\n",
      "est. 65\n",
      "NDCG: 0.6450746242295612\n",
      "est. 66\n",
      "NDCG: 0.6478534516963091\n",
      "est. 67\n",
      "NDCG: 0.6471732539886778\n",
      "est. 68\n",
      "NDCG: 0.6468164297667417\n",
      "est. 69\n",
      "NDCG: 0.6423040411689065\n",
      "est. 70\n",
      "NDCG: 0.6422920826483857\n",
      "est. 71\n",
      "NDCG: 0.6455377733165567\n",
      "est. 72\n",
      "NDCG: 0.6458705091340975\n",
      "est. 73\n",
      "NDCG: 0.6460853337564252\n",
      "est. 74\n",
      "NDCG: 0.6461457779461687\n",
      "est. 75\n",
      "NDCG: 0.6484866535121744\n",
      "est. 76\n",
      "NDCG: 0.6476304456591606\n",
      "est. 77\n",
      "NDCG: 0.6463150774890726\n",
      "est. 78\n",
      "NDCG: 0.648457904430953\n",
      "est. 79\n",
      "NDCG: 0.6466159773143855\n",
      "est. 80\n",
      "NDCG: 0.6455498435957865\n",
      "est. 81\n",
      "NDCG: 0.6453763795169917\n",
      "est. 82\n",
      "NDCG: 0.643816739320755\n",
      "est. 83\n",
      "NDCG: 0.6445129811763763\n",
      "est. 84\n",
      "NDCG: 0.6434841501441869\n",
      "est. 85\n",
      "NDCG: 0.643163192001256\n",
      "est. 86\n",
      "NDCG: 0.640937132591551\n",
      "est. 87\n",
      "NDCG: 0.6401723196560686\n",
      "est. 88\n",
      "NDCG: 0.6393033411692489\n",
      "est. 89\n",
      "NDCG: 0.637382311238484\n",
      "est. 90\n",
      "NDCG: 0.6373203406957063\n",
      "est. 91\n",
      "NDCG: 0.6371070827272806\n",
      "est. 92\n",
      "NDCG: 0.6371710672974586\n",
      "est. 93\n",
      "NDCG: 0.6391684375703335\n",
      "est. 94\n",
      "NDCG: 0.637174205346541\n",
      "est. 95\n",
      "NDCG: 0.6372032714161006\n",
      "est. 96\n",
      "NDCG: 0.6365434290333227\n",
      "est. 97\n",
      "NDCG: 0.636242497373711\n",
      "est. 98\n",
      "NDCG: 0.6356185627254572\n",
      "est. 99\n",
      "NDCG: 0.6361219127747145\n"
     ]
    }
   ],
   "source": [
    "sample_length = int(subsamples * ys_train.size(0))\n",
    "colsample_bytree_length = int(colsample_bytree * X_train.size(1))\n",
    "\n",
    "train_preds = torch.zeros_like(ys_train)\n",
    "for i in range(n_estimators):\n",
    "    print(f'est. {i}')\n",
    "\n",
    "    tree, f_ind = train_one_tree(i, train_preds)\n",
    "\n",
    "    trees.append(tree)\n",
    "    f_inds.append(f_ind)\n",
    "\n",
    "    preds -= lr * torch.FloatTensor(tree.predict(X_train[:, feature_ind])).reshape(-1,1)\n",
    "    \n",
    "    ys_pred = predict(X_test)\n",
    "    print(f'NDCG: {_calc_data_ndcg(query_ids_test, ys_test, ys_pred)}')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg: 0.6715075127009688\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.0159],\n",
       "         [ 0.9958],\n",
       "         [-0.1382],\n",
       "         [ 0.4877],\n",
       "         [-0.0995],\n",
       "         [-0.0645],\n",
       "         [-0.1082],\n",
       "         [ 0.2266],\n",
       "         [ 0.2180],\n",
       "         [ 0.3969]]),\n",
       " tensor([[2.],\n",
       "         [2.],\n",
       "         [0.],\n",
       "         [2.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [2.],\n",
       "         [1.],\n",
       "         [0.]]))"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'ndcg: {_calc_data_ndcg(query_ids_train, ys_train, preds)}')\n",
    "preds[:10], ys_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg: 0.6361219127747145\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.0293],\n",
       "         [-0.4662],\n",
       "         [-0.2975],\n",
       "         [ 0.2016],\n",
       "         [-0.5488],\n",
       "         [ 0.3072],\n",
       "         [-0.2759],\n",
       "         [-0.3473],\n",
       "         [ 0.1107],\n",
       "         [-0.0062]]),\n",
       " tensor([[2.],\n",
       "         [1.],\n",
       "         [3.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [2.]]))"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = torch.zeros_like(ys_test)\n",
    "for tree, f in zip(trees, f_inds):\n",
    "    res -= lr * torch.FloatTensor(tree.predict(X_test[:,f])).reshape(-1,1)\n",
    "\n",
    "print(f'ndcg: {_calc_data_ndcg(query_ids_test, ys_test, res)}')\n",
    "res[:10], ys_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ranking",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
